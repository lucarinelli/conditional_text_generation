{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "One_Notebook_To_Rule_Them_All.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "636e166a9ec94f5789ccb60dfd33a2f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4941da13e760421d85d05599133ca7a8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6415d5d11a97402690c94c69aa076cbf",
              "IPY_MODEL_f1fa7006af794242b9fa51404a1ce5b1"
            ]
          }
        },
        "4941da13e760421d85d05599133ca7a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6415d5d11a97402690c94c69aa076cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_95ef9a0ed2674d9c8b4f40e530be57a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e788b6c31e0c480495ac1a6a42502d91"
          }
        },
        "f1fa7006af794242b9fa51404a1ce5b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7c72f7571a3b47fca4a3c509930ccb7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 235/? [00:00&lt;00:00, 411.43 tables/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb9b2475ae4a42068e0eee607cd6a0de"
          }
        },
        "95ef9a0ed2674d9c8b4f40e530be57a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e788b6c31e0c480495ac1a6a42502d91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c72f7571a3b47fca4a3c509930ccb7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb9b2475ae4a42068e0eee607cd6a0de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ccb0bf66b734704b4a14c7130523b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7826147bf8c74b0bb383e2c1d63f1f2e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b10eb94c63646d4926077a59b48d7e9",
              "IPY_MODEL_66fc5609db8840bd8b4a496f3e85dd22"
            ]
          }
        },
        "7826147bf8c74b0bb383e2c1d63f1f2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b10eb94c63646d4926077a59b48d7e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b93b488244424a87bb46fc9f62c00e28",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37e9c2aabe5547bfb32c1f5232d5936b"
          }
        },
        "66fc5609db8840bd8b4a496f3e85dd22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_030c9138eed04d8dab332ea854a3dd11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/? [00:00&lt;00:00, 156.29 tables/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a592824f716a42dcbfdf4ea9106408b1"
          }
        },
        "b93b488244424a87bb46fc9f62c00e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37e9c2aabe5547bfb32c1f5232d5936b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "030c9138eed04d8dab332ea854a3dd11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a592824f716a42dcbfdf4ea9106408b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcf3e575fd2f427baf40f283d35e3e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_34023c1413e84a2cb2f76688eb4dd96d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f4161604a66146f69322691a3e3df9b4",
              "IPY_MODEL_ce9a3c35d7c64d38b64237d455255b8e"
            ]
          }
        },
        "34023c1413e84a2cb2f76688eb4dd96d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4161604a66146f69322691a3e3df9b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6790d03ecb694f61bf03d47c85019d14",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_821526f47e59425696bfd66e2989495f"
          }
        },
        "ce9a3c35d7c64d38b64237d455255b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_13c8d735af3d41d0ac189a2e86e83ce0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:06&lt;00:00,  3.07s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7898ec4135d94acbb724c1c732ae9a4a"
          }
        },
        "6790d03ecb694f61bf03d47c85019d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "821526f47e59425696bfd66e2989495f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13c8d735af3d41d0ac189a2e86e83ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7898ec4135d94acbb724c1c732ae9a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "959331cfa15e49a9a9b6b1f344004aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1010042fbfa2418cbd6354f09aeb7b4f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b9b4e2c7e0b648ab98627cb46daa3449",
              "IPY_MODEL_5fbf294ef55a48b5bb6869e8cbd83505"
            ]
          }
        },
        "1010042fbfa2418cbd6354f09aeb7b4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9b4e2c7e0b648ab98627cb46daa3449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8f9e5afab9264b11acddc0d066763f89",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84007673242c4a7e8036d407b6b57228"
          }
        },
        "5fbf294ef55a48b5bb6869e8cbd83505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_33feb2f8053a4de8b0b3d3240f144d8e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  2.43ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_770327d3df89428dbbf626b87f13157e"
          }
        },
        "8f9e5afab9264b11acddc0d066763f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84007673242c4a7e8036d407b6b57228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33feb2f8053a4de8b0b3d3240f144d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "770327d3df89428dbbf626b87f13157e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae3b7b654dbf429cb36f8a088b68258c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d4f28d7bf5643e1b9721978e12b27bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9f1120d9ddce46bdac838eb7c123c595",
              "IPY_MODEL_800b094cd94d40c18681ae0b67b54fb4"
            ]
          }
        },
        "9d4f28d7bf5643e1b9721978e12b27bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f1120d9ddce46bdac838eb7c123c595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_a7101208b14042dbb41dea8f9c1934ea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 488.22MB of 488.22MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5e57fd53bde4579a3fd636125080f31"
          }
        },
        "800b094cd94d40c18681ae0b67b54fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e3bda882a22a495982c9c8c77edc625f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b8486d577b649b7bf33b5376cbb8070"
          }
        },
        "a7101208b14042dbb41dea8f9c1934ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5e57fd53bde4579a3fd636125080f31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3bda882a22a495982c9c8c77edc625f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b8486d577b649b7bf33b5376cbb8070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucarinelli/conditional_text_generation/blob/main/notebooks/One_Notebook_To_Rule_Them_All.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEx06PvebUnT"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r-HBtLQd2U9"
      },
      "source": [
        "## Check allocated GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0ZFIlpZd1Xk",
        "outputId": "48405a91-e553-44df-ed99-bfcd98411cd7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May 25 18:45:40 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi6YIukebcAm"
      },
      "source": [
        "## Install needed python packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRZEIV-zWmi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c22f5c-583e-4327-bac4-8bcf3f590f36"
      },
      "source": [
        "!pip install --quiet transformers datasets tokenizers sacrebleu wandb"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.3MB 3.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 225kB 19.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 18.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8MB 35.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 35.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 32.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 37.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 33.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 35.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86aJ9wg9AhWx"
      },
      "source": [
        "## Connect to WandB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "O0wjibP8Ak_p",
        "outputId": "ad5cd505-4226-4012-a46f-d46551e65471"
      },
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk1mJeT-fiur"
      },
      "source": [
        "## Set experiment parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s3Ve3l58mFX",
        "outputId": "ddf3b73a-94da-4c09-842c-80c6ac5582c1"
      },
      "source": [
        "%env WANDB_PROJECT=ctrl_dry_runs\n",
        "%env WANDB_ENTITY=polito_aiml2021_textgen\n",
        "\n",
        "experiment_parameters = dict(\n",
        "    run_name = \"exp1\",  # String, experiment name\n",
        "    use_control_codes = True,  # True/False, enable conditional text generation or do basic text generation\n",
        "    force_dataset_update = False, # True/False, enable database updates even if it is already present on the file system\n",
        "    control_codes_type = \"special_token\",  # \"special_token\"/\"separators\"\n",
        "    use_supercategories = True,  # True/False, add supercategories as control codes \n",
        "    use_categories = False, # True/False, add categories as control codes    \n",
        "    use_control_codes_powerset = False,  # True/False, use powerset of control codes for each caption to augment dataset\n",
        "    max_control_codes_per_caption = 3,  # positive integer, maximum number of control codes to use with one caption during training\n",
        "    limited_run = True, # if set to True, the datasets will be reduced in size\n",
        "    max_train_set_len = 1500,  # positive integer, maximum number of items for the training set used\n",
        "    max_val_set_len = 150,  # positive integer, maximum number of items for the validation set used\n",
        "    model=\"gpt2\",  # we tested \"distilgpt2\" and \"gpt2\" for now\n",
        "    #save_model_path = \"OUTPUT\",\n",
        "    #random_seed = 42,  # integer, random seed used anywhere it could be useful to add some determinism\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: WANDB_PROJECT=ctrl_dry_runs\n",
            "env: WANDB_ENTITY=polito_aiml2021_textgen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBhNFP3c9h-Y",
        "outputId": "1139c15a-86d0-4193-97b5-d086b07c0a39"
      },
      "source": [
        "%env WANDB_LOG_MODEL=true\n",
        "%env WANDB_WATCH=all\n",
        "%env WANDB_SILENT=true"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: WANDB_LOG_MODEL=true\n",
            "env: WANDB_WATCH=all\n",
            "env: WANDB_SILENT=true\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPSvgf5wfoWI"
      },
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./data/results\",  # output directory\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=3,  # total # of training epochs\n",
        "    per_device_train_batch_size=64,  # batch size per device during training\n",
        "    per_device_eval_batch_size=1,  # batch size for evaluation\n",
        "    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./data/logs',  # directory for storing logs\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    report_to=\"wandb\",\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdD-oyY-pZwO"
      },
      "source": [
        "#TODO integrations with drive for checkpoints? It would work only in colab... not on azure or locally... should be parametrized?\n",
        "\n",
        "#TODO integration with WandB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUKg6vYrcBv8"
      },
      "source": [
        "# Dataset\n",
        "We download and load the COCO captions dataset.\n",
        "\n",
        "We join in a single item the caption for an image with the categories and/or supercategories associated to objects present in the image.\n",
        "Categories and/or supercategories are used as control codes depending on the experiment settings.\n",
        "\n",
        "The dataset is then post processed to train the model with different combinations of control codes for each caption, depending on the experiment parameters. The output of the postprocessing is saved on .txt files that are then loaded and further handled by the Dataset class provided by HuggingFace datasets (used for its performance and caching abilities).\n",
        "\n",
        "Here we start with the functions needed to download the COCO captions dataset and preprocess it for our use case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcVIj08WcHMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52bfa930-fae6-491c-cfcf-a90054fcce57"
      },
      "source": [
        "#TODO: Should we move this to an external file? Probably not since it is interesting to show?\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess  # to run sh commands\n",
        "import json\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from itertools import chain, combinations, groupby\n",
        "\n",
        "!mkdir data\n",
        "DATA_PATH=\"./data\"\n",
        "\n",
        "def download_annotations_dataset(data_path=DATA_PATH):\n",
        "    # download only if don't have it already\n",
        "    if not os.path.isdir(os.path.join(data_path,\"annotations\")):\n",
        "        if not os.path.exists(data_path):\n",
        "            os.makedirs(data_path)\n",
        "        subprocess.run([\"wget\",\"-P\", data_path, \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"])\n",
        "        subprocess.run([\"unzip\", \"-d\", data_path, os.path.join(data_path,\"annotations_trainval2017.zip\")])\n",
        "\n",
        "def map_and_join_dataset(data_instances, data_captions):\n",
        "    if not experiment_parameters[\"use_categories\"] and not experiment_parameters[\"use_supercategories\"]:\n",
        "        print(\"One of categories and supercategories has to be used!\")\n",
        "        sys.exit()\n",
        "    categories_data_dict = dict(map(lambda c: (c[\"id\"], c), data_instances[\"categories\"])) # <category_id, category>\n",
        "    annotations_data_mapped = map(lambda c: (c[\"image_id\"], c), data_instances[\"annotations\"]) # <image_id, annotation>\n",
        "    annotations_data_dict = {}\n",
        "    for a in annotations_data_mapped:\n",
        "        if a[0] in annotations_data_dict:\n",
        "            annotations_data_dict[a[0]] += [a[1]]\n",
        "        else:\n",
        "            annotations_data_dict[a[0]] = [a[1]]\n",
        "    captions_data_list = list(map(lambda c: (c[\"image_id\"], c), data_captions[\"annotations\"]))\n",
        "    captions_data_dict = dict()\n",
        "    for image_id, image_captions in groupby(captions_data_list, lambda x: x[0]):\n",
        "      image_captions_dict = dict()\n",
        "      for caption in image_captions:\n",
        "        image_captions_dict[caption[1][\"id\"]]=caption[1]\n",
        "      captions_data_dict[image_id]=image_captions_dict\n",
        "\n",
        "    dataset = []\n",
        "    control_codes_dict = {}\n",
        "    no_category_counter = 0\n",
        "\n",
        "    for image_id, captions in captions_data_dict.items():\n",
        "        item = {\"captions\": captions, \"categories\": []}\n",
        "        if image_id in annotations_data_dict:\n",
        "            tmp_categories_dict = {}\n",
        "            for a in annotations_data_dict[image_id]:\n",
        "                category_name = categories_data_dict[a[\"category_id\"]][\"name\"]\n",
        "                supercategory_name = categories_data_dict[a[\"category_id\"]][\"supercategory\"]\n",
        "                if experiment_parameters[\"use_categories\"]:\n",
        "                    tmp_categories_dict[category_name] = 1\n",
        "                    control_codes_dict[category_name] = 1\n",
        "                if experiment_parameters[\"use_supercategories\"]:\n",
        "                  tmp_categories_dict[supercategory_name] = 1\n",
        "                  control_codes_dict[supercategory_name] = 1\n",
        "            item[\"categories\"]=list(tmp_categories_dict.keys())\n",
        "        if len(item[\"categories\"])==0:\n",
        "            no_category_counter += 1\n",
        "        else: dataset += [item]\n",
        "\n",
        "    print(\"There are \"+str(no_category_counter)+\" captions without a category\")\n",
        "    return dataset, list(control_codes_dict.keys())\n",
        "\n",
        "def load_or_setup_dataset(data_path=DATA_PATH, split='train'):\n",
        "    if not split in ['train', 'val']:\n",
        "        print(\"Unknown split: \"+split)\n",
        "        sys.exit()\n",
        "    if not experiment_parameters[\"force_dataset_update\"] and os.path.isfile(os.path.join(data_path, \"dataset_with_ctrl_\"+split+\".json\")):\n",
        "        print (\"Dataset json file, loading dataset...\")\n",
        "        with open(os.path.join(data_path, \"dataset_with_ctrl_\"+split+\".json\"), \"r\") as read_file:\n",
        "            dataset = json.load(read_file)\n",
        "        with open(os.path.join(data_path, \"control_codes_\"+split+\".json\"), \"r\") as read_file:\n",
        "            control_codes = json.load(read_file)\n",
        "    else:\n",
        "        print (\"Dataset json file does not exist, creating dataset from scratch...\")\n",
        "        download_annotations_dataset(data_path=data_path)\n",
        "        with open(os.path.join(data_path,\"annotations/instances_\"+split+\"2017.json\"), \"r\") as read_file:\n",
        "            data_instances = json.load(read_file)\n",
        "\n",
        "        with open(os.path.join(data_path,\"annotations/captions_\"+split+\"2017.json\"), \"r\") as read_file:\n",
        "            data_captions = json.load(read_file)\n",
        "\n",
        "        dataset, control_codes = map_and_join_dataset(data_instances, data_captions)\n",
        "\n",
        "        with open(os.path.join(data_path,\"control_codes_\"+split+\".json\"), 'w') as outfile:\n",
        "            json.dump(control_codes, outfile)\n",
        "        \n",
        "        with open(os.path.join(data_path,\"dataset_with_ctrl_\"+split+\".json\"), 'w') as outfile:\n",
        "            json.dump(dataset, outfile)\n",
        "    return dataset, control_codes"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dTXHhsBfcf5"
      },
      "source": [
        "Actually call the functions previously defined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn1Y5hvlcc5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834ca260-87d1-4179-96e8-7c598df12828"
      },
      "source": [
        "data_path=DATA_PATH\n",
        "\n",
        "dataset_train, categories = load_or_setup_dataset(data_path=data_path, split=\"train\")\n",
        "dataset_val, _ = load_or_setup_dataset(data_path=data_path, split=\"val\")\n",
        "\n",
        "print(\"There are \"+str(len(dataset_train))+\" captions in total (train)\")\n",
        "print(\"There are \"+str(len(dataset_val))+\" captions in total (val)\")\n",
        "\n",
        "print(\"The following \"+str(len(categories))+\" categories are present in the dataset:\")\n",
        "print(categories)\n",
        "\n",
        "if experiment_parameters[\"use_control_codes\"] and experiment_parameters[\"control_codes_type\"] == \"special_token\":\n",
        "    control_codes = []\n",
        "    for category in categories:\n",
        "        control_codes += [\"<CTRL:\"+category.replace(\" \",\"_\")+\">\"]\n",
        "\n",
        "    print(\"Processed control codes:\")\n",
        "    print(control_codes)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset json file does not exist, creating dataset from scratch...\n",
            "There are 1021 captions without a category\n",
            "Dataset json file does not exist, creating dataset from scratch...\n",
            "There are 48 captions without a category\n",
            "There are 117266 captions in total (train)\n",
            "There are 4952 captions in total (val)\n",
            "The following 12 categories are present in the dataset:\n",
            "['vehicle', 'indoor', 'kitchen', 'appliance', 'person', 'outdoor', 'furniture', 'food', 'sports', 'animal', 'accessory', 'electronic']\n",
            "Processed control codes:\n",
            "['<CTRL:vehicle>', '<CTRL:indoor>', '<CTRL:kitchen>', '<CTRL:appliance>', '<CTRL:person>', '<CTRL:outdoor>', '<CTRL:furniture>', '<CTRL:food>', '<CTRL:sports>', '<CTRL:animal>', '<CTRL:accessory>', '<CTRL:electronic>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMaQOJO5cfql"
      },
      "source": [
        "import multiprocessing as mp\n",
        "\n",
        "chunk_size = 500\n",
        "\n",
        "def powerset(iterable, max_size=None):\n",
        "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
        "    s = list(iterable)\n",
        "    if max_size is None:\n",
        "        return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
        "    else:\n",
        "        return chain.from_iterable(combinations(s, r) for r in range(min(max_size, len(s)+1)))\n",
        "\n",
        "def process_chunk(chunk):\n",
        "    chunk_number = chunk[0]\n",
        "    chunk_items = chunk[1]\n",
        "    data_path = chunk[2]\n",
        "    split = chunk[3]\n",
        "    txt_file = os.path.join(data_path, \"captions_\"+split+\"_\"+str(chunk_number)+\".txt\")\n",
        "    with open(txt_file, 'w') as captions_txt:\n",
        "        for item in chunk_items:\n",
        "            if experiment_parameters[\"use_control_codes\"]:\n",
        "                if experiment_parameters[\"use_control_codes_powerset\"]:\n",
        "                    control_codes_combinations = powerset(item['categories'], experiment_parameters[\"max_control_codes_per_caption\"])\n",
        "                else:\n",
        "                    control_codes_combinations = [item['categories']]\n",
        "            else:\n",
        "                control_codes_combinations = [[]]\n",
        "            for control_codes_combination in control_codes_combinations:\n",
        "                pre_control_codes_string=\"\"\n",
        "                for category in sorted(control_codes_combination):\n",
        "                    if experiment_parameters[\"control_codes_type\"] == \"special_token\":\n",
        "                        pre_control_codes_string+=\"<CTRL:\"+category.replace(\" \",\"_\")+\">\"\n",
        "                    elif experiment_parameters[\"control_codes_type\"] == \"separators\":\n",
        "                        pre_control_codes_string+=category+\", \"\n",
        "                    else:\n",
        "                        print(\"ERROR: wrong control code type\")\n",
        "                        return -1  # TODO here we could fail better\n",
        "                captions_txt.write(pre_control_codes_string+'<|startoftext|>'+item['caption']+'<|endoftext|>\\n')\n",
        "\n",
        "\n",
        "def write_txt_chunks(dataset, split, data_path, chunk_size):\n",
        "    chunks = [dataset[start:min(start+chunk_size,len(dataset))] for start in range(0, len(dataset), chunk_size)]\n",
        "    pool = mp.Pool(processes=8)\n",
        "    pool.map(process_chunk, [(chunk_n, chunk_items, data_path, split) for chunk_n, chunk_items in enumerate(chunks)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBoWOFcGd1VS"
      },
      "source": [
        "write_txt_chunks(dataset_train, \"train\", data_path, chunk_size)\n",
        "write_txt_chunks(dataset_val, \"val\", data_path, chunk_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSeE_0ZOcif-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "636e166a9ec94f5789ccb60dfd33a2f1",
            "4941da13e760421d85d05599133ca7a8",
            "6415d5d11a97402690c94c69aa076cbf",
            "f1fa7006af794242b9fa51404a1ce5b1",
            "95ef9a0ed2674d9c8b4f40e530be57a4",
            "e788b6c31e0c480495ac1a6a42502d91",
            "7c72f7571a3b47fca4a3c509930ccb7a",
            "fb9b2475ae4a42068e0eee607cd6a0de",
            "8ccb0bf66b734704b4a14c7130523b71",
            "7826147bf8c74b0bb383e2c1d63f1f2e",
            "1b10eb94c63646d4926077a59b48d7e9",
            "66fc5609db8840bd8b4a496f3e85dd22",
            "b93b488244424a87bb46fc9f62c00e28",
            "37e9c2aabe5547bfb32c1f5232d5936b",
            "030c9138eed04d8dab332ea854a3dd11",
            "a592824f716a42dcbfdf4ea9106408b1"
          ]
        },
        "outputId": "6afbf0e5-98b0-4a35-8376-5feb75b9da74"
      },
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "import glob\n",
        "\n",
        "dataset_train, dataset_val = load_dataset('text', data_files={'train': glob.glob('./data/captions_train_*.txt'), 'val': glob.glob('./data/captions_val_*.txt')}, split=['train', 'val'])\n",
        "print(\"Augmented dataset has: \"+str(len(dataset_train))+\" train elements and \"+str(len(dataset_val))+\" validation elements\")\n",
        "\n",
        "if experiment_parameters[\"limited_run\"]: # shuffle and cut the datasets\n",
        "  dataset_train = dataset_train.shuffle(42).select(range(experiment_parameters[\"max_train_set_len\"]))\n",
        "  dataset_val = dataset_val.shuffle(42).select(range(experiment_parameters[\"max_val_set_len\"]))\n",
        "  print(\"We take only a small part of that: \"+str(len(dataset_train))+\" train elements and \"+str(len(dataset_val))+\" validation elements\")\n",
        "else: # just shuffle them\n",
        "  dataset_train = dataset_train.shuffle(42)\n",
        "  dataset_val = dataset_val.shuffle(42)\n",
        "  print(\"Train elements: \"+str(len(dataset_train))+\"\\nValidation elements: \"+str(len(dataset_val)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-27c067ddb5594cd7\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/text/default-27c067ddb5594cd7/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "636e166a9ec94f5789ccb60dfd33a2f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ccb0bf66b734704b4a14c7130523b71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-27c067ddb5594cd7/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n",
            "Augmented dataset has: 644379 train elements and 27339 validation elements\n",
            "We take only a small part of that: 1500 train elements and 150 validation elements\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oqZ10H3dTIw"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCANYNf9XWet",
        "outputId": "564ad48c-1109-424b-ed0f-1026d7f9f4cb"
      },
      "source": [
        "from transformers import GPT2TokenizerFast\n",
        "\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(experiment_parameters['model'])\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "print(\"Tokenizer before added special tokens \"+str(len(tokenizer)))\n",
        "\n",
        "if experiment_parameters[\"use_control_codes\"] and experiment_parameters[\"control_codes_type\"] == \"special_token\":\n",
        "    special_tokens_dict = {'additional_special_tokens': control_codes}\n",
        "    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "    print(\"added \"+str(num_added_toks)+\" tokens to the pretrained tokenizer\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizer before added special tokens 50257\n",
            "added 12 tokens to the pretrained tokenizer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "bcf3e575fd2f427baf40f283d35e3e6a",
            "34023c1413e84a2cb2f76688eb4dd96d",
            "f4161604a66146f69322691a3e3df9b4",
            "ce9a3c35d7c64d38b64237d455255b8e",
            "6790d03ecb694f61bf03d47c85019d14",
            "821526f47e59425696bfd66e2989495f",
            "13c8d735af3d41d0ac189a2e86e83ce0",
            "7898ec4135d94acbb724c1c732ae9a4a",
            "959331cfa15e49a9a9b6b1f344004aec",
            "1010042fbfa2418cbd6354f09aeb7b4f",
            "b9b4e2c7e0b648ab98627cb46daa3449",
            "5fbf294ef55a48b5bb6869e8cbd83505",
            "8f9e5afab9264b11acddc0d066763f89",
            "84007673242c4a7e8036d407b6b57228",
            "33feb2f8053a4de8b0b3d3240f144d8e",
            "770327d3df89428dbbf626b87f13157e"
          ]
        },
        "id": "UpJ76wxIXXQq",
        "outputId": "83c72b5e-0ffe-4976-b601-061ada146b8a"
      },
      "source": [
        "def encode(examples):\n",
        "    encoded = tokenizer(examples['text'], truncation=True, max_length=64, padding=\"max_length\")\n",
        "    encoded['labels'] = encoded['input_ids']\n",
        "    return encoded\n",
        "\n",
        "dataset_train_encoded = dataset_train.map(encode, batched=True)\n",
        "dataset_val_encoded = dataset_val.map(encode, batched=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcf3e575fd2f427baf40f283d35e3e6a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "959331cfa15e49a9a9b6b1f344004aec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQwzZXNKdZ0H"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFMrleG6XZ7l",
        "outputId": "6242c7c4-f3b3-4390-a597-236d6ae856dc"
      },
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(experiment_parameters['model'], pad_token_id=tokenizer.eos_token_id)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50269, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7QMoShFuc10"
      },
      "source": [
        "#TODO add the possibility to freeze some layers? Add an experiment parameter for this?\n",
        "#TODO print the model structure?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6ape3DYdcJ0"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvJTYqvEXe0e"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CePKXiMzX3hl"
      },
      "source": [
        "import datasets\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions\n",
        "  metric = datasets.load_metric('sacrebleu')\n",
        "\n",
        "  preds = tokenizer.batch_decode(preds)\n",
        "  labels = tokenizer.batch_decode(labels)\n",
        "  labels = [ [label] for label in labels]\n",
        "\n",
        "  final_score = metric.compute(predictions=preds, references=labels)\n",
        "  return {\n",
        "      'bleu': final_score\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH1NnAXsX-i1"
      },
      "source": [
        "#TODO: Should we move this to an external file?\n",
        "\n",
        "from transformers import Trainer\n",
        "\n",
        "import collections\n",
        "import inspect\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "import sys\n",
        "import tempfile\n",
        "import time\n",
        "import warnings\n",
        "from logging import StreamHandler\n",
        "from pathlib import Path\n",
        "from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "# Integrations must be imported before ML frameworks:\n",
        "from transformers.integrations import (  # isort: split\n",
        "    default_hp_search_backend,\n",
        "    get_reporting_integration_callbacks,\n",
        "    hp_params,\n",
        "    is_fairscale_available,\n",
        "    is_optuna_available,\n",
        "    is_ray_tune_available,\n",
        "    run_hp_search_optuna,\n",
        "    run_hp_search_ray,\n",
        "    deepspeed_init,\n",
        "    is_deepspeed_zero3_enabled,\n",
        ")\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from packaging import version\n",
        "from torch import nn\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data.dataset import Dataset, IterableDataset\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import __version__\n",
        "from transformers.configuration_utils import PretrainedConfig\n",
        "from transformers.data.data_collator import DataCollator, DataCollatorWithPadding, default_data_collator\n",
        "from transformers.debug_utils import DebugOption, DebugUnderflowOverflow\n",
        "from transformers.dependency_versions_check import dep_version_check\n",
        "from transformers.file_utils import (\n",
        "    CONFIG_NAME,\n",
        "    WEIGHTS_NAME,\n",
        "    PushToHubMixin,\n",
        "    is_apex_available,\n",
        "    is_datasets_available,\n",
        "    is_in_notebook,\n",
        "    is_sagemaker_dp_enabled,\n",
        "    is_sagemaker_mp_enabled,\n",
        "    is_torch_tpu_available,\n",
        "    is_training_run_on_sagemaker,\n",
        ")\n",
        "from transformers.modelcard import TrainingSummary\n",
        "from transformers.modeling_utils import PreTrainedModel, unwrap_model\n",
        "from transformers.optimization import Adafactor, AdamW, get_scheduler\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
        "from transformers.trainer_callback import (\n",
        "    CallbackHandler,\n",
        "    DefaultFlowCallback,\n",
        "    PrinterCallback,\n",
        "    ProgressCallback,\n",
        "    TrainerCallback,\n",
        "    TrainerControl,\n",
        "    TrainerState,\n",
        ")\n",
        "from transformers.trainer_pt_utils import (\n",
        "    DistributedLengthGroupedSampler,\n",
        "    DistributedSamplerWithLoop,\n",
        "    DistributedTensorGatherer,\n",
        "    IterableDatasetShard,\n",
        "    LabelSmoother,\n",
        "    LengthGroupedSampler,\n",
        "    SequentialDistributedSampler,\n",
        "    ShardSampler,\n",
        "    distributed_broadcast_scalars,\n",
        "    distributed_concat,\n",
        "    find_batch_size,\n",
        "    get_parameter_names,\n",
        "    nested_concat,\n",
        "    nested_detach,\n",
        "    nested_numpify,\n",
        "    nested_truncate,\n",
        "    nested_xla_mesh_reduce,\n",
        "    reissue_pt_warnings,\n",
        ")\n",
        "from transformers.trainer_utils import (\n",
        "    PREFIX_CHECKPOINT_DIR,\n",
        "    BestRun,\n",
        "    EvalLoopOutput,\n",
        "    EvalPrediction,\n",
        "    HPSearchBackend,\n",
        "    PredictionOutput,\n",
        "    ShardedDDPOption,\n",
        "    TrainerMemoryTracker,\n",
        "    TrainOutput,\n",
        "    default_compute_objective,\n",
        "    default_hp_space,\n",
        "    denumpify_detensorize,\n",
        "    get_last_checkpoint,\n",
        "    set_seed,\n",
        "    speed_metrics,\n",
        ")\n",
        "from transformers.training_args import ParallelMode, TrainingArguments\n",
        "from transformers.utils import logging\n",
        "from transformers.utils.modeling_auto_mapping import MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES\n",
        "\n",
        "\n",
        "_is_torch_generator_available = False\n",
        "_is_native_amp_available = False\n",
        "\n",
        "DEFAULT_CALLBACKS = [DefaultFlowCallback]\n",
        "DEFAULT_PROGRESS_CALLBACK = ProgressCallback\n",
        "\n",
        "if is_in_notebook():\n",
        "    from transformers.utils.notebook import NotebookProgressCallback\n",
        "\n",
        "    DEFAULT_PROGRESS_CALLBACK = NotebookProgressCallback\n",
        "\n",
        "if is_apex_available():\n",
        "    from apex import amp\n",
        "\n",
        "if version.parse(torch.__version__) >= version.parse(\"1.6\"):\n",
        "    _is_torch_generator_available = True\n",
        "    _is_native_amp_available = True\n",
        "    from torch.cuda.amp import autocast\n",
        "\n",
        "if is_datasets_available():\n",
        "    import datasets\n",
        "\n",
        "if is_torch_tpu_available():\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    import torch_xla.debug.metrics as met\n",
        "    import torch_xla.distributed.parallel_loader as pl\n",
        "\n",
        "if is_fairscale_available():\n",
        "    dep_version_check(\"fairscale\")\n",
        "    import fairscale\n",
        "    from fairscale.nn.data_parallel import FullyShardedDataParallel as FullyShardedDDP\n",
        "    from fairscale.nn.data_parallel import ShardedDataParallel as ShardedDDP\n",
        "    from fairscale.nn.wrap import auto_wrap\n",
        "    from fairscale.optim import OSS\n",
        "    from fairscale.optim.grad_scaler import ShardedGradScaler\n",
        "\n",
        "if is_sagemaker_dp_enabled():\n",
        "    import smdistributed.dataparallel.torch.distributed as dist\n",
        "    from smdistributed.dataparallel.torch.parallel.distributed import DistributedDataParallel as DDP\n",
        "else:\n",
        "    import torch.distributed as dist\n",
        "\n",
        "if is_sagemaker_mp_enabled():\n",
        "    import smdistributed.modelparallel.torch as smp\n",
        "\n",
        "    from transformers.trainer_pt_utils import smp_forward_backward, smp_forward_only, smp_gather, smp_nested_concat\n",
        "\n",
        "if is_training_run_on_sagemaker():\n",
        "    logging.add_handler(StreamHandler(sys.stdout))\n",
        "\n",
        "\n",
        "if TYPE_CHECKING:\n",
        "    import optuna\n",
        "\n",
        "logger = logging.get_logger(__name__)\n",
        "\n",
        "class MyTrainer(Trainer):\n",
        "    def evaluation_loop(\n",
        "        self,\n",
        "        dataloader: DataLoader,\n",
        "        description: str,\n",
        "        prediction_loss_only: Optional[bool] = None,\n",
        "        ignore_keys: Optional[List[str]] = None,\n",
        "        metric_key_prefix: str = \"eval\",\n",
        "    ) -> EvalLoopOutput:\n",
        "        \"\"\"\n",
        "        Prediction/evaluation loop, shared by :obj:`Trainer.evaluate()` and :obj:`Trainer.predict()`.\n",
        "\n",
        "        Works both with or without labels.\n",
        "        \"\"\"\n",
        "        prediction_loss_only = (\n",
        "            prediction_loss_only if prediction_loss_only is not None else self.args.prediction_loss_only\n",
        "        )\n",
        "\n",
        "        # if eval is called w/o train init deepspeed here\n",
        "        if self.args.deepspeed and not self.deepspeed:\n",
        "\n",
        "            # XXX: eval doesn't have `resume_from_checkpoint` arg but we should be able to do eval\n",
        "            # from the checkpoint eventually\n",
        "            deepspeed_engine, _, _ = deepspeed_init(self, num_training_steps=0, resume_from_checkpoint=None)\n",
        "            self.model = deepspeed_engine.module\n",
        "            self.model_wrapped = deepspeed_engine\n",
        "            self.deepspeed = deepspeed_engine\n",
        "            # XXX: we don't need optim/sched for inference, but this needs to be sorted out, since\n",
        "            # for example the Z3-optimizer is a must for zero3 to work even for inference - what we\n",
        "            # don't need is the deepspeed basic optimizer which is self.optimizer.optimizer\n",
        "            deepspeed_engine.optimizer.optimizer = None\n",
        "            deepspeed_engine.lr_scheduler = None\n",
        "\n",
        "        model = self._wrap_model(self.model, training=False)\n",
        "\n",
        "        # if full fp16 is wanted on eval and this ``evaluation`` or ``predict`` isn't called while\n",
        "        # ``train`` is running, halve it first and then put on device\n",
        "        if not self.is_in_train and self.args.fp16_full_eval:\n",
        "            model = model.half().to(self.args.device)\n",
        "\n",
        "        batch_size = dataloader.batch_size\n",
        "\n",
        "        logger.info(f\"***** Running {description} *****\")\n",
        "        if isinstance(dataloader.dataset, collections.abc.Sized):\n",
        "            logger.info(f\"  Num examples = {self.num_examples(dataloader)}\")\n",
        "        else:\n",
        "            logger.info(\"  Num examples: Unknown\")\n",
        "        logger.info(f\"  Batch size = {batch_size}\")\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        self.callback_handler.eval_dataloader = dataloader\n",
        "        # Do this before wrapping.\n",
        "        eval_dataset = dataloader.dataset\n",
        "\n",
        "        if is_torch_tpu_available():\n",
        "            dataloader = pl.ParallelLoader(dataloader, [self.args.device]).per_device_loader(self.args.device)\n",
        "\n",
        "        if self.args.past_index >= 0:\n",
        "            self._past = None\n",
        "\n",
        "        # Initialize containers\n",
        "        # losses/preds/labels on GPU/TPU (accumulated for eval_accumulation_steps)\n",
        "        losses_host = None\n",
        "        preds_host = None\n",
        "        labels_host = None\n",
        "        # losses/preds/labels on CPU (final containers)\n",
        "        all_losses = None\n",
        "        all_preds = None\n",
        "        all_labels = None\n",
        "        # Will be useful when we have an iterable dataset so don't know its length.\n",
        "\n",
        "        observed_num_examples = 0\n",
        "        # Main evaluation loop\n",
        "        for step, inputs in enumerate(dataloader):\n",
        "            # Update the observed num examples\n",
        "            observed_batch_size = find_batch_size(inputs)\n",
        "            if observed_batch_size is not None:\n",
        "                observed_num_examples += observed_batch_size\n",
        "\n",
        "            # Prediction step\n",
        "            loss, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)\n",
        "\n",
        "            # Update containers on host\n",
        "            if loss is not None:\n",
        "                losses = self._nested_gather(loss.repeat(batch_size))\n",
        "                losses_host = losses if losses_host is None else torch.cat((losses_host, losses), dim=0)\n",
        "            ############################\n",
        "            if logits is not None:\n",
        "                logits = self._pad_across_processes(logits)\n",
        "                logits = self._nested_gather(logits)\n",
        "                logits_reduced = np.argmax(logits.cpu(), axis=-1) # Obtain a single value instead of a vector, for memory efficiency\n",
        "                preds_host = logits_reduced if preds_host is None else nested_concat(preds_host, logits_reduced, padding_index=-100)\n",
        "                # preds_host = logits if preds_host is None else nested_concat(preds_host, logits, padding_index=-100)\n",
        "            ############################\n",
        "            if labels is not None:\n",
        "                labels = self._pad_across_processes(labels)\n",
        "                labels = self._nested_gather(labels)\n",
        "                labels_host = labels if labels_host is None else nested_concat(labels_host, labels, padding_index=-100)\n",
        "            self.control = self.callback_handler.on_prediction_step(self.args, self.state, self.control)\n",
        "\n",
        "            # Gather all tensors and put them back on the CPU if we have done enough accumulation steps.\n",
        "            if self.args.eval_accumulation_steps is not None and (step + 1) % self.args.eval_accumulation_steps == 0:\n",
        "                if losses_host is not None:\n",
        "                    losses = nested_numpify(losses_host)\n",
        "                    all_losses = losses if all_losses is None else np.concatenate((all_losses, losses), axis=0)\n",
        "                if preds_host is not None:\n",
        "                    logits = nested_numpify(preds_host)\n",
        "                    all_preds = logits if all_preds is None else nested_concat(all_preds, logits, padding_index=-100)\n",
        "                if labels_host is not None:\n",
        "                    labels = nested_numpify(labels_host)\n",
        "                    all_labels = (\n",
        "                        labels if all_labels is None else nested_concat(all_labels, labels, padding_index=-100)\n",
        "                    )\n",
        "\n",
        "                # Set back to None to begin a new accumulation\n",
        "                losses_host, preds_host, labels_host = None, None, None\n",
        "\n",
        "        if self.args.past_index and hasattr(self, \"_past\"):\n",
        "            # Clean the state at the end of the evaluation loop\n",
        "            delattr(self, \"_past\")\n",
        "\n",
        "        # Gather all remaining tensors and put them back on the CPU\n",
        "        if losses_host is not None:\n",
        "            losses = nested_numpify(losses_host)\n",
        "            all_losses = losses if all_losses is None else np.concatenate((all_losses, losses), axis=0)\n",
        "        if preds_host is not None:\n",
        "            logits = nested_numpify(preds_host)\n",
        "            all_preds = logits if all_preds is None else nested_concat(all_preds, logits, padding_index=-100)\n",
        "        if labels_host is not None:\n",
        "            labels = nested_numpify(labels_host)\n",
        "            all_labels = labels if all_labels is None else nested_concat(all_labels, labels, padding_index=-100)\n",
        "\n",
        "        # Number of samples\n",
        "        if not isinstance(eval_dataset, IterableDataset):\n",
        "            num_samples = len(eval_dataset)\n",
        "        elif isinstance(eval_dataset, IterableDatasetShard):\n",
        "            num_samples = eval_dataset.num_examples\n",
        "        else:\n",
        "            num_samples = observed_num_examples\n",
        "\n",
        "        # Number of losses has been rounded to a multiple of batch_size and in a distributed training, the number of\n",
        "        # samplers has been rounded to a multiple of batch_size, so we truncate.\n",
        "        if all_losses is not None:\n",
        "            all_losses = all_losses[:num_samples]\n",
        "        if all_preds is not None:\n",
        "            all_preds = nested_truncate(all_preds, num_samples)\n",
        "        if all_labels is not None:\n",
        "            all_labels = nested_truncate(all_labels, num_samples)\n",
        "\n",
        "        # Metrics!\n",
        "        if self.compute_metrics is not None and all_preds is not None and all_labels is not None:\n",
        "            metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))\n",
        "        else:\n",
        "            metrics = {}\n",
        "\n",
        "        # To be JSON-serializable, we need to remove numpy types or zero-d tensors\n",
        "        metrics = denumpify_detensorize(metrics)\n",
        "\n",
        "        if all_losses is not None:\n",
        "            metrics[f\"{metric_key_prefix}_loss\"] = all_losses.mean().item()\n",
        "\n",
        "        # Prefix all keys with metric_key_prefix + '_'\n",
        "        for key in list(metrics.keys()):\n",
        "            if not key.startswith(f\"{metric_key_prefix}_\"):\n",
        "                metrics[f\"{metric_key_prefix}_{key}\"] = metrics.pop(key)\n",
        "\n",
        "        return EvalLoopOutput(predictions=all_preds, label_ids=all_labels, metrics=metrics, num_samples=num_samples)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HJPAhYqXfhk"
      },
      "source": [
        "dataset_train_encoded.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "dataset_val_encoded.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "trainer = MyTrainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=dataset_train_encoded,         # training dataset\n",
        "    eval_dataset=dataset_val_encoded,\n",
        "    compute_metrics=compute_metrics,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HodDpeuIXli2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "a3e0b138-e221-4849-d789-152e806bc1d8"
      },
      "source": [
        "trainer.train()\n",
        "\n",
        "config = wandb.config\n",
        "config.update(experiment_parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">./data/results</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/polito_aiml2021_textgen/ctrl_dry_runs\" target=\"_blank\">https://wandb.ai/polito_aiml2021_textgen/ctrl_dry_runs</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/polito_aiml2021_textgen/ctrl_dry_runs/runs/f5ivsr2p\" target=\"_blank\">https://wandb.ai/polito_aiml2021_textgen/ctrl_dry_runs/runs/f5ivsr2p</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210523_101344-f5ivsr2p</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [72/72 04:15, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>75.199097</td>\n",
              "      <td>{'score': 2.690892406096247, 'counts': [14240, 7011, 276, 98], 'totals': [47864, 47714, 47564, 47414], 'precisions': [29.750961056326258, 14.69380056168001, 0.5802707930367504, 0.2066900071708778], 'bp': 1.0, 'sys_len': 47864, 'ref_len': 36306}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>12.051480</td>\n",
              "      <td>{'score': 0.09835943589719567, 'counts': [3071, 945, 298, 117], 'totals': [6602, 6452, 6302, 6152], 'precisions': [46.51620720993638, 14.646621202727836, 4.728657569025706, 1.901820546163849], 'bp': 0.011117413081925208, 'sys_len': 6602, 'ref_len': 36306}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.660257</td>\n",
              "      <td>{'score': 90.33514640426056, 'counts': [34619, 33668, 33090, 32685], 'totals': [37318, 37168, 37018, 36868], 'precisions': [92.7675652500134, 90.5832974601808, 89.38894591820196, 88.65411739177607], 'bp': 1.0, 'sys_len': 37318, 'ref_len': 36306}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F_val6rXooF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742,
          "referenced_widgets": [
            "ae3b7b654dbf429cb36f8a088b68258c",
            "9d4f28d7bf5643e1b9721978e12b27bc",
            "9f1120d9ddce46bdac838eb7c123c595",
            "800b094cd94d40c18681ae0b67b54fb4",
            "a7101208b14042dbb41dea8f9c1934ea",
            "c5e57fd53bde4579a3fd636125080f31",
            "e3bda882a22a495982c9c8c77edc625f",
            "7b8486d577b649b7bf33b5376cbb8070"
          ]
        },
        "outputId": "880d7db6-e9a9-4b7f-ae93-b5454de8816d"
      },
      "source": [
        "trainer.save_model(\"./data/results\")\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 699<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae3b7b654dbf429cb36f8a088b68258c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 487.43MB of 487.43MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210523_101344-f5ivsr2p/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210523_101344-f5ivsr2p/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>eval/loss</td><td>2.66026</td></tr><tr><td>eval/runtime</td><td>19.1156</td></tr><tr><td>eval/samples_per_second</td><td>7.847</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>72</td></tr><tr><td>_runtime</td><td>220</td></tr><tr><td>_timestamp</td><td>1621765044</td></tr><tr><td>_step</td><td>3</td></tr><tr><td>train/train_runtime</td><td>219.5541</td></tr><tr><td>train/train_samples_per_second</td><td>0.328</td></tr><tr><td>train/total_flos</td><td>0</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>eval/loss</td><td>█▂▁</td></tr><tr><td>eval/runtime</td><td>▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>▇█▁</td></tr><tr><td>train/epoch</td><td>▁▅██</td></tr><tr><td>train/global_step</td><td>▁▅██</td></tr><tr><td>_runtime</td><td>▁▄██</td></tr><tr><td>_timestamp</td><td>▁▄██</td></tr><tr><td>_step</td><td>▁▃▆█</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 1 media file(s), 6 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">./data/results</strong>: <a href=\"https://wandb.ai/polito_aiml2021_textgen/ctrl_dry_runs/runs/f5ivsr2p\" target=\"_blank\">https://wandb.ai/polito_aiml2021_textgen/ctrl_dry_runs/runs/f5ivsr2p</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab-ssh-ctrl.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucarinelli/conditional_text_generation/blob/main/notebooks/experiments/gpt2_separators_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzvKtEY1n70i"
      },
      "source": [
        "#GPT2 experiments of Conditional Text Generation\n",
        "\n",
        "Add a description here..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIX2LYnwnFAi"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bFrORkonIiB"
      },
      "source": [
        "SSH for developing and debugging purposes, useful to quickly explore all the files involved in the repo and add or fix things here and there. \n",
        "\n",
        "Do not enable if you are just running the experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xngy64TnWsZc"
      },
      "source": [
        "# Install colab_ssh on google colab\n",
        "!pip install colab_ssh --upgrade\n",
        "\n",
        "from colab_ssh import launch_ssh_cloudflared\n",
        "# Comment or un-comment the next line to disable/enable ssh\n",
        "launch_ssh_cloudflared(password=\"2N6.ufRjL,Zp:GfcJuh?TQ\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrHucla4ntGJ"
      },
      "source": [
        "Mount goole drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fzslv_tr6NSO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRHiVbN_nvkG"
      },
      "source": [
        "Check allocated GPU, hope for something better than a K80..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IFU1IJK5kov"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPwdVHRaoOjR"
      },
      "source": [
        "Install the needed python packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5r3LDgDlHSg"
      },
      "source": [
        "!pip install --quiet transformers datasets tokenizers sacrebleu wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xMxYJTloRbF"
      },
      "source": [
        "Clone our repository to get our utilities and overrides"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9u6kIsYlM1Z"
      },
      "source": [
        "!git clone https://github.com/lucarinelli/conditional_text_generation.git /content/conditional_text_generation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJUEHq91oT0X"
      },
      "source": [
        "Add our repository `src` folder to python path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPUBUKq1lIcd"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "module_path = os.path.abspath(\"/content/conditional_text_generation/src\")\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gbm_PcQoaGS"
      },
      "source": [
        "Setup and connect to Weights and Biases to store logs and results\n",
        "\n",
        "**REMEMBER TO SET WANDB_PROJECT TO THE CORRECT VALUE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyfQCwYEoZ2V"
      },
      "source": [
        "import wandb\n",
        "\n",
        "%env WANDB_PROJECT=ctrl_dry_runs\n",
        "%env WANDB_ENTITY=polito_aiml2021_textgen\n",
        "%env WANDB_LOG_MODEL=true\n",
        "%env WANDB_WATCH=all\n",
        "%env WANDB_SILENT=true\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLuS1oEWofMh"
      },
      "source": [
        "Set training arguments and other experiment parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsLGoRrKlNc1"
      },
      "source": [
        "from experiment_parameters import ExperimentParameters\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "project_name = \"gpt2-separators\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/conditional_text_generation/runs/data/results/{}\".format(project_name),  # output directory\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=3,  # total # of training epochs\n",
        "    per_device_train_batch_size=64,  # batch size per device during training\n",
        "    per_device_eval_batch_size=1,  # batch size for evaluation\n",
        "    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='/content/drive/MyDrive/conditional_text_generation/runs/data/logs/{}'.format(project_name),  # directory for storing logs\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    report_to=\"wandb\",\n",
        "    load_best_model_at_end=True,\n",
        "    remove_unused_columns=False\n",
        ")\n",
        "\n",
        "#TODO experiment parameters run name is not actually used\n",
        "experiment_parameters = ExperimentParameters(training_args=training_args, force_dataset_update=True, control_codes_type = \"separators\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCETuptWl5CI"
      },
      "source": [
        "#Database\n",
        "We download and load the COCO captions dataset.\n",
        "\n",
        "We join in a single item the caption for an image with the categories and/or supercategories associated to objects present in the image.\n",
        "Categories and/or supercategories are used as control codes depending on the experiment settings.\n",
        "\n",
        "The dataset is post processed to train the model with different combinations of control codes for each caption, depending on the experiment parameters. The output of the postprocessing is saved on .json files that are then loaded and further handled by the Dataset class provided by HuggingFace datasets (used for its performance and caching abilities)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCgsI-i_lRpM"
      },
      "source": [
        "from captions_dataset import *\n",
        "\n",
        "dataset_train, dataset_val, control_codes, references = get_dataset(experiment_parameters, data_path=\"/content/data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spR4wdPDl7Af"
      },
      "source": [
        "#Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNurmccRmFCV"
      },
      "source": [
        "tokenizer = get_tokenizer(experiment_parameters, control_codes)\n",
        "\n",
        "dataset_train_encoded = encode_and_format_dataset(dataset_train, DatasetType.TRAIN, tokenizer)\n",
        "dataset_val_encoded = encode_and_format_dataset(dataset_val, DatasetType.EVAL, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5imyKzNmKkO"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWgvhSUDmL8_"
      },
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(experiment_parameters.model, pad_token_id=tokenizer.eos_token_id)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KgRj9D9pX1c"
      },
      "source": [
        "#Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rB5hn1lmZoA"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Srrf6Ro9ma1G"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4fVEC1Jmiff"
      },
      "source": [
        "from our_trainer import *\n",
        "\n",
        "training_args.references = references\n",
        "\n",
        "trainer = OurTrainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=dataset_train_encoded,         # training dataset\n",
        "    eval_dataset=dataset_val_encoded,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer = tokenizer\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PupwP8LHmqWf"
      },
      "source": [
        "trainer.train(True)\n",
        "\n",
        "config = wandb.config\n",
        "config.update(experiment_parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydvNF5i-mtgY"
      },
      "source": [
        "trainer.save_model(training_args.output_dir)\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
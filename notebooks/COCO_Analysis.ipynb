{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COCO Analysis.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZgTgu47mjCedLVC0Gho+G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucarinelli/conditional_text_generation/blob/main/notebooks/COCO_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao3J4b8BCcxq"
      },
      "source": [
        "# Import utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWUcoztQCY7D"
      },
      "source": [
        "!rm -r conditional_text_generation\n",
        "!git clone https://github.com/lucarinelli/conditional_text_generation.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v04bA9kCWvJ"
      },
      "source": [
        "!pip install import-ipynb\n",
        "\n",
        "%cd conditional_text_generation/notebooks\n",
        "\n",
        "import import_ipynb\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from CtrlUtilities import *\n",
        "\n",
        "%cd ../.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbpLMsKVCawo"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO8A0yTOTZDz"
      },
      "source": [
        "experiment_parameters[\"run_name\"] = \"exp1\"  # String, experiment name\n",
        "experiment_parameters[\"use_control_codes\"] = True  # True/False, enable conditional text generation or do basic text generation\n",
        "experiment_parameters[\"force_dataset_update\"] = True # True/False, enable database updates even if it is already present on the file system\n",
        "experiment_parameters[\"control_codes_type\"] = \"special_token\" # \"special_token\"/\"separators\"\n",
        "experiment_parameters[\"use_supercategories\"] = True  # True/False, add supercategories as control codes \n",
        "experiment_parameters[\"use_categories\"] = False # True/False, add categories as control codes    \n",
        "experiment_parameters[\"use_control_codes_powerset\"] = False  # True/False, use powerset of control codes for each caption to augment dataset\n",
        "experiment_parameters[\"max_control_codes_per_caption\"] = 3  # positive integer, maximum number of control codes to use with one caption during training\n",
        "experiment_parameters[\"limited_run\"] = True # if set to True, the datasets will be reduced in size\n",
        "experiment_parameters[\"max_train_set_len\"] = 1500  # positive integer, maximum number of items for the training set used\n",
        "experiment_parameters[\"max_val_set_len\"] = 1000  # positive integer, maximum number of items for the validation set used\n",
        "experiment_parameters[\"model\"]= \"gpt2\"  # we tested \"distilgpt2\" and \"gpt2\" for now\n",
        "    #save_model_path = \"OUTPUT\",\n",
        "    #random_seed = 42,  # integer, random seed used anywhere it could be useful to add some determinism\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LoxzffhCm8V"
      },
      "source": [
        "!mkdir data\n",
        "DATA_PATH=\"./data\"\n",
        "data_path=DATA_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bigk8H5eCqGK"
      },
      "source": [
        "# Coco Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gZZQZIBZ3Mj"
      },
      "source": [
        "def computeAverageOnDataset(dataset, fieldExtractor):\n",
        "  count = 0\n",
        "  minV = None\n",
        "  maxV = None\n",
        "  for i in dataset:\n",
        "    l = len(fieldExtractor(i)) \n",
        "    count += l\n",
        "    if minV is None or l < minV: minV = l\n",
        "    if maxV is None or l > maxV: maxV = l\n",
        "  return count / len(dataset), minV, maxV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSZFNdMOcfoc"
      },
      "source": [
        "def logControlCodeAnalysis(type):\n",
        "  print(\"Creating dataset using {}\".format(type))\n",
        "  dataset_train, _, _ = load_or_setup_dataset(data_path=data_path, split=\"train\")\n",
        "  number_of_categories = list(map(lambda e: len(e[\"categories\"]), dataset_train))\n",
        "  average, min, max = computeAverageOnDataset(dataset_train, lambda e: e[\"categories\"])\n",
        "  percentile = 100 - len(list(filter(lambda nc: nc > average, number_of_categories))) / len(dataset_train) *100\n",
        "\n",
        "  print(\"For {} the average number of control codes per caption is {}.\\nIt's the {:.0f}th percentile. Minimum is {}. Maximum is {}\".format(type, average, percentile, min, max))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_gtmm1ZSwmU"
      },
      "source": [
        "experiment_parameters[\"use_supercategories\"] = True\n",
        "experiment_parameters[\"use_categories\"] = False\n",
        "logControlCodeAnalysis(\"supercategories only\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FQiXVOuWIx4"
      },
      "source": [
        "experiment_parameters[\"use_supercategories\"] = False\n",
        "experiment_parameters[\"use_categories\"] = True\n",
        "logControlCodeAnalysis(\"categories only\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1giwtjuXy6Z"
      },
      "source": [
        "experiment_parameters[\"use_supercategories\"] = True\n",
        "experiment_parameters[\"use_categories\"] = True\n",
        "logControlCodeAnalysis(\"categories and supercategories\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_aNBSc8a-Aw"
      },
      "source": [
        "experiment_parameters[\"use_supercategories\"] = True\n",
        "experiment_parameters[\"use_categories\"] = False\n",
        "dataset_train, _, categories = load_or_setup_dataset(data_path=data_path, split=\"train\")\n",
        "averageChar, minC, maxC = computeAverageOnDataset(dataset_train, lambda e: e[\"caption\"])\n",
        "print(\"Average length of captions is {} chars. Min {} and max {}\".format(averageChar, minC, maxC))\n",
        "averageWords, minW, maxW = computeAverageOnDataset(dataset_train, lambda x: x[\"caption\"].split())\n",
        "print(\"Average length of captions is {} words. Min {} and max {}\".format(averageWords, minW, maxW))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDVOAn7ufGJZ"
      },
      "source": [
        "print(\"Database has {} entries.\".format(len(dataset_train)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python2",
   "display_name": "Python 2",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\nRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\nRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\nRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\nRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\nRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\nRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\nRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\nRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset json file, loading dataset...\n",
      "There are 118287 captions in total (train)\n",
      "The following 91 categories are present in the dataset:\n",
      "['bicycle', 'vehicle', 'clock', 'indoor', 'cup', 'kitchen', 'sink', 'appliance', 'vase', 'car', 'motorcycle', 'person', 'bench', 'outdoor', 'airplane', 'bottle', 'toilet', 'furniture', 'potted plant', 'toothbrush', 'refrigerator', 'oven', 'apple', 'food', 'banana', 'surfboard', 'sports', 'bowl', 'spoon', 'traffic light', 'cat', 'animal', 'cow', 'handbag', 'accessory', 'umbrella', 'book', 'skateboard', 'horse', 'cake', 'donut', 'chair', 'cell phone', 'electronic', 'laptop', 'mouse', 'tv', 'dog', 'knife', 'orange', 'microwave', 'backpack', 'bus', 'dining table', 'truck', 'bird', 'giraffe', 'suitcase', 'boat', 'skis', 'fire hydrant', 'toaster', 'wine glass', 'sheep', 'remote', 'scissors', 'tie', 'kite', 'broccoli', 'stop sign', 'teddy bear', 'fork', 'keyboard', 'elephant', 'carrot', 'parking meter', 'snowboard', 'pizza', 'baseball glove', 'frisbee', 'train', 'couch', 'zebra', 'hair drier', 'bed', 'sandwich', 'baseball bat', 'sports ball', 'hot dog', 'tennis racket', 'bear']\n",
      "Processed control codes:\n",
      "['<CTRL:bicycle>', '<CTRL:vehicle>', '<CTRL:clock>', '<CTRL:indoor>', '<CTRL:cup>', '<CTRL:kitchen>', '<CTRL:sink>', '<CTRL:appliance>', '<CTRL:vase>', '<CTRL:car>', '<CTRL:motorcycle>', '<CTRL:person>', '<CTRL:bench>', '<CTRL:outdoor>', '<CTRL:airplane>', '<CTRL:bottle>', '<CTRL:toilet>', '<CTRL:furniture>', '<CTRL:potted_plant>', '<CTRL:toothbrush>', '<CTRL:refrigerator>', '<CTRL:oven>', '<CTRL:apple>', '<CTRL:food>', '<CTRL:banana>', '<CTRL:surfboard>', '<CTRL:sports>', '<CTRL:bowl>', '<CTRL:spoon>', '<CTRL:traffic_light>', '<CTRL:cat>', '<CTRL:animal>', '<CTRL:cow>', '<CTRL:handbag>', '<CTRL:accessory>', '<CTRL:umbrella>', '<CTRL:book>', '<CTRL:skateboard>', '<CTRL:horse>', '<CTRL:cake>', '<CTRL:donut>', '<CTRL:chair>', '<CTRL:cell_phone>', '<CTRL:electronic>', '<CTRL:laptop>', '<CTRL:mouse>', '<CTRL:tv>', '<CTRL:dog>', '<CTRL:knife>', '<CTRL:orange>', '<CTRL:microwave>', '<CTRL:backpack>', '<CTRL:bus>', '<CTRL:dining_table>', '<CTRL:truck>', '<CTRL:bird>', '<CTRL:giraffe>', '<CTRL:suitcase>', '<CTRL:boat>', '<CTRL:skis>', '<CTRL:fire_hydrant>', '<CTRL:toaster>', '<CTRL:wine_glass>', '<CTRL:sheep>', '<CTRL:remote>', '<CTRL:scissors>', '<CTRL:tie>', '<CTRL:kite>', '<CTRL:broccoli>', '<CTRL:stop_sign>', '<CTRL:teddy_bear>', '<CTRL:fork>', '<CTRL:keyboard>', '<CTRL:elephant>', '<CTRL:carrot>', '<CTRL:parking_meter>', '<CTRL:snowboard>', '<CTRL:pizza>', '<CTRL:baseball_glove>', '<CTRL:frisbee>', '<CTRL:train>', '<CTRL:couch>', '<CTRL:zebra>', '<CTRL:hair_drier>', '<CTRL:bed>', '<CTRL:sandwich>', '<CTRL:baseball_bat>', '<CTRL:sports_ball>', '<CTRL:hot_dog>', '<CTRL:tennis_racket>', '<CTRL:bear>']\n",
      "Writing txt\n",
      "txt file already exists, nothing to do here...\n",
      "No tokenizer provided, you will need to provide one later through the tokenize method!\n",
      "Dataset json file, loading dataset...\n",
      "There are 5000 captions in total (val)\n",
      "The following 91 categories are present in the dataset:\n",
      "['motorcycle', 'vehicle', 'tv', 'electronic', 'chair', 'furniture', 'laptop', 'mouse', 'keyboard', 'backpack', 'accessory', 'sports ball', 'sports', 'bottle', 'kitchen', 'potted plant', 'book', 'indoor', 'vase', 'cup', 'toilet', 'sink', 'appliance', 'car', 'person', 'bench', 'outdoor', 'handbag', 'truck', 'spoon', 'cake', 'food', 'bowl', 'dining table', 'bird', 'animal', 'cat', 'clock', 'cell phone', 'remote', 'bed', 'microwave', 'oven', 'banana', 'dog', 'couch', 'giraffe', 'cow', 'airplane', 'traffic light', 'refrigerator', 'orange', 'apple', 'train', 'bicycle', 'zebra', 'kite', 'scissors', 'knife', 'umbrella', 'horse', 'toaster', 'fork', 'sheep', 'teddy bear', 'bus', 'fire hydrant', 'sandwich', 'stop sign', 'suitcase', 'tie', 'toothbrush', 'skateboard', 'parking meter', 'frisbee', 'skis', 'carrot', 'donut', 'wine glass', 'surfboard', 'boat', 'hair drier', 'pizza', 'snowboard', 'broccoli', 'hot dog', 'elephant', 'baseball bat', 'baseball glove', 'bear', 'tennis racket']\n",
      "Processed control codes:\n",
      "['<CTRL:motorcycle>', '<CTRL:vehicle>', '<CTRL:tv>', '<CTRL:electronic>', '<CTRL:chair>', '<CTRL:furniture>', '<CTRL:laptop>', '<CTRL:mouse>', '<CTRL:keyboard>', '<CTRL:backpack>', '<CTRL:accessory>', '<CTRL:sports_ball>', '<CTRL:sports>', '<CTRL:bottle>', '<CTRL:kitchen>', '<CTRL:potted_plant>', '<CTRL:book>', '<CTRL:indoor>', '<CTRL:vase>', '<CTRL:cup>', '<CTRL:toilet>', '<CTRL:sink>', '<CTRL:appliance>', '<CTRL:car>', '<CTRL:person>', '<CTRL:bench>', '<CTRL:outdoor>', '<CTRL:handbag>', '<CTRL:truck>', '<CTRL:spoon>', '<CTRL:cake>', '<CTRL:food>', '<CTRL:bowl>', '<CTRL:dining_table>', '<CTRL:bird>', '<CTRL:animal>', '<CTRL:cat>', '<CTRL:clock>', '<CTRL:cell_phone>', '<CTRL:remote>', '<CTRL:bed>', '<CTRL:microwave>', '<CTRL:oven>', '<CTRL:banana>', '<CTRL:dog>', '<CTRL:couch>', '<CTRL:giraffe>', '<CTRL:cow>', '<CTRL:airplane>', '<CTRL:traffic_light>', '<CTRL:refrigerator>', '<CTRL:orange>', '<CTRL:apple>', '<CTRL:train>', '<CTRL:bicycle>', '<CTRL:zebra>', '<CTRL:kite>', '<CTRL:scissors>', '<CTRL:knife>', '<CTRL:umbrella>', '<CTRL:horse>', '<CTRL:toaster>', '<CTRL:fork>', '<CTRL:sheep>', '<CTRL:teddy_bear>', '<CTRL:bus>', '<CTRL:fire_hydrant>', '<CTRL:sandwich>', '<CTRL:stop_sign>', '<CTRL:suitcase>', '<CTRL:tie>', '<CTRL:toothbrush>', '<CTRL:skateboard>', '<CTRL:parking_meter>', '<CTRL:frisbee>', '<CTRL:skis>', '<CTRL:carrot>', '<CTRL:donut>', '<CTRL:wine_glass>', '<CTRL:surfboard>', '<CTRL:boat>', '<CTRL:hair_drier>', '<CTRL:pizza>', '<CTRL:snowboard>', '<CTRL:broccoli>', '<CTRL:hot_dog>', '<CTRL:elephant>', '<CTRL:baseball_bat>', '<CTRL:baseball_glove>', '<CTRL:bear>', '<CTRL:tennis_racket>']\n",
      "Writing txt\n",
      "txt file already exists, nothing to do here...\n",
      "No tokenizer provided, you will need to provide one later through the tokenize method!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from captions_dataset import CaptionsDataset\n",
    "\n",
    "dataset_train = CaptionsDataset(split=\"train\")\n",
    "dataset_val = CaptionsDataset(split=\"val\")"
   ]
  },
  {
   "source": [
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\", bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "print(\"Tokenizer before added special tokens \"+str(len(tokenizer)))\n",
    "special_tokens_dict = {'additional_special_tokens': dataset_train.control_codes}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print(\"added \"+str(num_added_toks)+\" tokens to the pretrained tokenizer\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\", pad_token_id=tokenizer.eos_token_id)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
      "Tokenizer before added special tokens 50259\n",
      "added 91 tokens to the pretrained tokenizer\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Embedding(50350, 768)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading pretokenized dataset! (train)\n",
      "Tokenizing dataset! (val)\n",
      "Saving tokenized dataset! (val)\n"
     ]
    }
   ],
   "source": [
    "dataset_train.tokenize(tokenizer, load_tokenized=True)\n",
    "dataset_val.tokenize(tokenizer, load_tokenized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",          # output directory\n",
    "    num_train_epochs=3,              # total # of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=dataset_train,         # training dataset\n",
    "    eval_dataset=dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;31m# Data loader and number of training steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m         \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;31m# Setting up training control variables:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mget_train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trainer: training requires a train_dataset.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m         \u001b[0mtrain_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         return DataLoader(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_get_train_sampler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             elif (\n\u001b[1;32m    532\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_mode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mParallelMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAGEMAKER_MODEL_PARALLEL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m--> 104\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
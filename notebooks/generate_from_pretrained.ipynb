{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /home/lrinelli/.local/lib/python3.8/site-packages (4.5.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/lrinelli/.local/lib/python3.8/site-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/lrinelli/.local/lib/python3.8/site-packages (from transformers) (4.45.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: sacremoses in /home/lrinelli/.local/lib/python3.8/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/lrinelli/.local/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: filelock in /home/lrinelli/.local/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/lib/python3/dist-packages (from transformers) (1.17.4)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from transformers) (20.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /home/lrinelli/.local/lib/python3.8/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already up-to-date: torch in /home/lrinelli/.local/lib/python3.8/site-packages (1.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/lib/python3/dist-packages (from torch) (1.17.4)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /home/lrinelli/.local/lib/python3.8/site-packages (from torch) (3.7.4.2)\n",
      "Dataset json file, loading dataset...\n",
      "There are 118287 captions in total (train)\n",
      "The following 91 categories are present in the dataset:\n",
      "['bicycle', 'vehicle', 'clock', 'indoor', 'cup', 'kitchen', 'sink', 'appliance', 'vase', 'car', 'motorcycle', 'person', 'bench', 'outdoor', 'airplane', 'bottle', 'toilet', 'furniture', 'potted plant', 'toothbrush', 'refrigerator', 'oven', 'apple', 'food', 'banana', 'surfboard', 'sports', 'bowl', 'spoon', 'traffic light', 'cat', 'animal', 'cow', 'handbag', 'accessory', 'umbrella', 'book', 'skateboard', 'horse', 'cake', 'donut', 'chair', 'cell phone', 'electronic', 'laptop', 'mouse', 'tv', 'dog', 'knife', 'orange', 'microwave', 'backpack', 'bus', 'dining table', 'truck', 'bird', 'giraffe', 'suitcase', 'boat', 'skis', 'fire hydrant', 'toaster', 'wine glass', 'sheep', 'remote', 'scissors', 'tie', 'kite', 'broccoli', 'stop sign', 'teddy bear', 'fork', 'keyboard', 'elephant', 'carrot', 'parking meter', 'snowboard', 'pizza', 'baseball glove', 'frisbee', 'train', 'couch', 'zebra', 'hair drier', 'bed', 'sandwich', 'baseball bat', 'sports ball', 'hot dog', 'tennis racket', 'bear']\n",
      "Processed control codes:\n",
      "['<CTRL:bicycle>', '<CTRL:vehicle>', '<CTRL:clock>', '<CTRL:indoor>', '<CTRL:cup>', '<CTRL:kitchen>', '<CTRL:sink>', '<CTRL:appliance>', '<CTRL:vase>', '<CTRL:car>', '<CTRL:motorcycle>', '<CTRL:person>', '<CTRL:bench>', '<CTRL:outdoor>', '<CTRL:airplane>', '<CTRL:bottle>', '<CTRL:toilet>', '<CTRL:furniture>', '<CTRL:potted_plant>', '<CTRL:toothbrush>', '<CTRL:refrigerator>', '<CTRL:oven>', '<CTRL:apple>', '<CTRL:food>', '<CTRL:banana>', '<CTRL:surfboard>', '<CTRL:sports>', '<CTRL:bowl>', '<CTRL:spoon>', '<CTRL:traffic_light>', '<CTRL:cat>', '<CTRL:animal>', '<CTRL:cow>', '<CTRL:handbag>', '<CTRL:accessory>', '<CTRL:umbrella>', '<CTRL:book>', '<CTRL:skateboard>', '<CTRL:horse>', '<CTRL:cake>', '<CTRL:donut>', '<CTRL:chair>', '<CTRL:cell_phone>', '<CTRL:electronic>', '<CTRL:laptop>', '<CTRL:mouse>', '<CTRL:tv>', '<CTRL:dog>', '<CTRL:knife>', '<CTRL:orange>', '<CTRL:microwave>', '<CTRL:backpack>', '<CTRL:bus>', '<CTRL:dining_table>', '<CTRL:truck>', '<CTRL:bird>', '<CTRL:giraffe>', '<CTRL:suitcase>', '<CTRL:boat>', '<CTRL:skis>', '<CTRL:fire_hydrant>', '<CTRL:toaster>', '<CTRL:wine_glass>', '<CTRL:sheep>', '<CTRL:remote>', '<CTRL:scissors>', '<CTRL:tie>', '<CTRL:kite>', '<CTRL:broccoli>', '<CTRL:stop_sign>', '<CTRL:teddy_bear>', '<CTRL:fork>', '<CTRL:keyboard>', '<CTRL:elephant>', '<CTRL:carrot>', '<CTRL:parking_meter>', '<CTRL:snowboard>', '<CTRL:pizza>', '<CTRL:baseball_glove>', '<CTRL:frisbee>', '<CTRL:train>', '<CTRL:couch>', '<CTRL:zebra>', '<CTRL:hair_drier>', '<CTRL:bed>', '<CTRL:sandwich>', '<CTRL:baseball_bat>', '<CTRL:sports_ball>', '<CTRL:hot_dog>', '<CTRL:tennis_racket>', '<CTRL:bear>']\n",
      "Writing txt\n",
      "txt file already exists, nothing to do here...\n",
      "No tokenizer provided, you will need to provide one later through the tokenize method!\n",
      "Dataset json file, loading dataset...\n",
      "There are 5000 captions in total (val)\n",
      "The following 91 categories are present in the dataset:\n",
      "['motorcycle', 'vehicle', 'tv', 'electronic', 'chair', 'furniture', 'laptop', 'mouse', 'keyboard', 'backpack', 'accessory', 'sports ball', 'sports', 'bottle', 'kitchen', 'potted plant', 'book', 'indoor', 'vase', 'cup', 'toilet', 'sink', 'appliance', 'car', 'person', 'bench', 'outdoor', 'handbag', 'truck', 'spoon', 'cake', 'food', 'bowl', 'dining table', 'bird', 'animal', 'cat', 'clock', 'cell phone', 'remote', 'bed', 'microwave', 'oven', 'banana', 'dog', 'couch', 'giraffe', 'cow', 'airplane', 'traffic light', 'refrigerator', 'orange', 'apple', 'train', 'bicycle', 'zebra', 'kite', 'scissors', 'knife', 'umbrella', 'horse', 'toaster', 'fork', 'sheep', 'teddy bear', 'bus', 'fire hydrant', 'sandwich', 'stop sign', 'suitcase', 'tie', 'toothbrush', 'skateboard', 'parking meter', 'frisbee', 'skis', 'carrot', 'donut', 'wine glass', 'surfboard', 'boat', 'hair drier', 'pizza', 'snowboard', 'broccoli', 'hot dog', 'elephant', 'baseball bat', 'baseball glove', 'bear', 'tennis racket']\n",
      "Processed control codes:\n",
      "['<CTRL:motorcycle>', '<CTRL:vehicle>', '<CTRL:tv>', '<CTRL:electronic>', '<CTRL:chair>', '<CTRL:furniture>', '<CTRL:laptop>', '<CTRL:mouse>', '<CTRL:keyboard>', '<CTRL:backpack>', '<CTRL:accessory>', '<CTRL:sports_ball>', '<CTRL:sports>', '<CTRL:bottle>', '<CTRL:kitchen>', '<CTRL:potted_plant>', '<CTRL:book>', '<CTRL:indoor>', '<CTRL:vase>', '<CTRL:cup>', '<CTRL:toilet>', '<CTRL:sink>', '<CTRL:appliance>', '<CTRL:car>', '<CTRL:person>', '<CTRL:bench>', '<CTRL:outdoor>', '<CTRL:handbag>', '<CTRL:truck>', '<CTRL:spoon>', '<CTRL:cake>', '<CTRL:food>', '<CTRL:bowl>', '<CTRL:dining_table>', '<CTRL:bird>', '<CTRL:animal>', '<CTRL:cat>', '<CTRL:clock>', '<CTRL:cell_phone>', '<CTRL:remote>', '<CTRL:bed>', '<CTRL:microwave>', '<CTRL:oven>', '<CTRL:banana>', '<CTRL:dog>', '<CTRL:couch>', '<CTRL:giraffe>', '<CTRL:cow>', '<CTRL:airplane>', '<CTRL:traffic_light>', '<CTRL:refrigerator>', '<CTRL:orange>', '<CTRL:apple>', '<CTRL:train>', '<CTRL:bicycle>', '<CTRL:zebra>', '<CTRL:kite>', '<CTRL:scissors>', '<CTRL:knife>', '<CTRL:umbrella>', '<CTRL:horse>', '<CTRL:toaster>', '<CTRL:fork>', '<CTRL:sheep>', '<CTRL:teddy_bear>', '<CTRL:bus>', '<CTRL:fire_hydrant>', '<CTRL:sandwich>', '<CTRL:stop_sign>', '<CTRL:suitcase>', '<CTRL:tie>', '<CTRL:toothbrush>', '<CTRL:skateboard>', '<CTRL:parking_meter>', '<CTRL:frisbee>', '<CTRL:skis>', '<CTRL:carrot>', '<CTRL:donut>', '<CTRL:wine_glass>', '<CTRL:surfboard>', '<CTRL:boat>', '<CTRL:hair_drier>', '<CTRL:pizza>', '<CTRL:snowboard>', '<CTRL:broccoli>', '<CTRL:hot_dog>', '<CTRL:elephant>', '<CTRL:baseball_bat>', '<CTRL:baseball_glove>', '<CTRL:bear>', '<CTRL:tennis_racket>']\n",
      "Writing txt\n",
      "txt file already exists, nothing to do here...\n",
      "No tokenizer provided, you will need to provide one later through the tokenize method!\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers\n",
    "!pip3 install --upgrade torch \n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from captions_dataset import CaptionsDataset\n",
    "\n",
    "dataset_train = CaptionsDataset(data_path=\"../data\", split=\"train\")\n",
    "dataset_val = CaptionsDataset(data_path=\"../data\", split=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
      "Tokenizer before added special tokens 50259\n",
      "added 91 tokens to the pretrained tokenizer\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Embedding(50350, 768)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\", bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "print(\"Tokenizer before added special tokens \"+str(len(tokenizer)))\n",
    "special_tokens_dict = {'additional_special_tokens': dataset_train.control_codes}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print(\"added \"+str(num_added_toks)+\" tokens to the pretrained tokenizer\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = GPT2LMHeadModel.from_pretrained(\"../data/pretrained\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:  A person is holding a bottle of red wine and looking at it.\n\n\n1:  A person is standing on a beach looking in the distance.\n\n\n2:  A person is riding a snow board on a snowy slope.\n\n\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "prompt=\"<CTRL:indoor><|startoftext|> A person is\"\n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "\n",
    "model.eval()\n",
    "sample_outputs = model.generate(generated,do_sample=True,   \n",
    "                                top_k=100, \n",
    "                                max_length = 256,\n",
    "                                top_p=0.90, \n",
    "                                num_return_sequences=3)\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
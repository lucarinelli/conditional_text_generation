{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CTRL Distillation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNAFNnbdnW1P17DtFbHfbUb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucarinelli/conditional_text_generation/blob/main/CTRL_Distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wek-67EOByPv"
      },
      "source": [
        "# Import utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RljRLltlBz3K"
      },
      "source": [
        "!rm -r conditional_text_generation\n",
        "!git clone https://github.com/lucarinelli/conditional_text_generation.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz7DpZRwB1J9"
      },
      "source": [
        "!pip install import-ipynb\n",
        "\n",
        "%cd conditional_text_generation/notebooks\n",
        "\n",
        "import import_ipynb\n",
        "\n",
        "from Conditional_Text_Generation_Skeleton import *\n",
        "\n",
        "%cd ../.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg8e9K83xEDo"
      },
      "source": [
        "# WanDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05DCFj2axHN9"
      },
      "source": [
        "run = wandb.init()\n",
        "artifact = run.use_artifact('polito_aiml2021_textgen/ctrl_dry_runs/GPT2_supercategories_5_epochs_v1:v0', type='model')\n",
        "artifact_dir = artifact.download()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC2na-CpxIs3"
      },
      "source": [
        "#Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFcMmzxwJj3t"
      },
      "source": [
        "experiment_parameters[\"low_cuda\"]= True  # True/False, used to move some operations of the distil process on the cpu in order to don't overflow cuda memory\n",
        "experiment_parameters[\"training_args\"].temperature= 1\n",
        "experiment_parameters[\"max_train_set_len\"] = 12  # positive integer, maximum number of items for the training set used\n",
        "experiment_parameters[\"max_val_set_len\"] = 12  # positive integer, maximum number of items for the validation set used"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng0PgpQ_tyL-"
      },
      "source": [
        "tokenizer, dataset_train_encoded, dataset_val_encoded, references = initialize_env()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imiyipCwxLmQ"
      },
      "source": [
        "# Models\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD8w37XlEyLM"
      },
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(experiment_parameters['model'], pad_token_id=tokenizer.eos_token_id)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "teacher = GPT2LMHeadModel.from_pretrained(artifact_dir)\n",
        "teacher= teacher.cuda()\n",
        "teacher.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvO3BPzmxSCo"
      },
      "source": [
        "# Class room"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05rhE2pBFJ_F"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "class MyDistilTrainer(MyTrainer):\n",
        "    def __init__(self, \n",
        "        teacher: Union[PreTrainedModel, torch.nn.Module] = None,\n",
        "        model: Union[PreTrainedModel, torch.nn.Module] = None,\n",
        "        args: TrainingArguments = None,\n",
        "        data_collator: Optional[DataCollator] = None,\n",
        "        train_dataset: Optional[Dataset] = None,\n",
        "        eval_dataset: Optional[Dataset] = None,\n",
        "        tokenizer: Optional[PreTrainedTokenizerBase] = None,\n",
        "        model_init: Callable[[], PreTrainedModel] = None,\n",
        "        compute_metrics: Optional[Callable[[EvalPrediction], Dict]] = None,\n",
        "        callbacks: Optional[List[TrainerCallback]] = None,\n",
        "        optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None),): \n",
        "\n",
        "      self.teacher = teacher\n",
        "      super().__init__(model, args, data_collator,\n",
        "                       train_dataset, eval_dataset,\n",
        "                       tokenizer, model_init, compute_metrics, \n",
        "                       callbacks, optimizers)\n",
        "        \n",
        "      self.loss = nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "      with torch.no_grad():\n",
        "          teacher_output = teacher(**inputs)\n",
        "\n",
        "      student_output = self.model(**inputs)\n",
        "\n",
        "      student_logits = student_output.logits\n",
        "      teacher_logits = teacher_output.logits\n",
        "\n",
        "      if experiment_parameters[\"low_cuda\"] :\n",
        "          student_logits = student_logits.cpu()\n",
        "          teacher_logits = teacher_logits.cpu()\n",
        "        \n",
        "\n",
        "      student_sm = F.log_softmax(student_logits/self.args.temperature, dim=-1)\n",
        "      teacher_sm = F.softmax(teacher_logits/self.args.temperature, dim=-1)\n",
        "\n",
        "      loss = self.loss(input=student_sm, target=teacher_sm)\n",
        "\n",
        "      if experiment_parameters[\"low_cuda\"] :\n",
        "        loss = loss.cuda()\n",
        "       \n",
        "      return (loss, student_logits) if return_outputs else loss   \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzaelFywxX1i"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqJ5xtGfFFpF"
      },
      "source": [
        "trainer = MyDistilTrainer(\n",
        "    teacher = teacher,\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=experiment_parameters[\"training_args\"],                  # training arguments, defined above\n",
        "    train_dataset=dataset_train_encoded,         # training dataset\n",
        "    eval_dataset=dataset_val_encoded,\n",
        "    compute_metrics=lambda a,b: compute_metrics(tokenizer, references, a, b),\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ9FFO3ZFJcx"
      },
      "source": [
        "trainer.train()\n",
        "\n",
        "after_training(trainer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPz4IwWKD-9-"
      },
      "source": [
        "# "
      ]
    }
  ]
}